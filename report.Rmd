---
title: 'SWEET: results report'
author: "A. Umanets, PhD"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    theme: "yeti"
    toc: true
    toc_deapth: 4
    toc_float: true
    toc_title: "Table of Content"
    number_sections: false
---


```{r , message=FALSE, warning=FALSE, prompt=FALSE, results='hide', echo=FALSE}

libs.list <- c("phyloseq", "tidyverse", "ggsignif", "broom", "vegan", 
               "metagenomeSeq", "qiime2R", "picante", "phangorn", "FSA", 
               "knitr", "MicrobiomeStat", "ggvegan", "ggpmisc", "Maaslin2", 
               "kableExtra", "cowplot", "psych")

for (i in libs.list) {library(i, character.only = TRUE)}

rm(list = c("i", "libs.list"))

# Load data
load("out/supp/data_bundel.Rdata")
load("out/supp/alpha_res.Rdata")
load("out/supp/beta_res.Rdata")
load("out/supp/beta_pairs_res.Rdata")
load("out/supp/da_vis.Rdata")

#-------------------------------------------------------------------------------
# Custom function
#-------------------------------------------------------------------------------
plot_kable <- function(df, title) {
  
  tab.height <- (nrow(df)*40 + 80)
  
  if(tab.height > 400) {
    tab.height <- 400
  }
  
  kable(df, 
        caption = title, 
        row.names = FALSE) %>% 
  kable_styling(bootstrap_options = c("striped", 
                                      "hover", 
                                      "responsive"), 
                full_width = FALSE, 
                position = "left") %>% 
    scroll_box(width = "100%", height = paste0(tab.height, "px"))
  
}

#-----------------------------------------------------------------------------
# Function: dynamically change size of figures
#-----------------------------------------------------------------------------
subchunkify <- function(g, fig_height=7, fig_width=5) {
                        g_deparsed <- paste0(deparse(
                          function() {g}
                        ), collapse = '')
                        
                        sub_chunk <- paste0("`","``{r sub_chunk_", 
                                            floor(runif(1) * 10000), 
                                            ", fig.height=", fig_height, 
                                            ", fig.width=", fig_width, ", echo=FALSE}",
                                            "\n(", g_deparsed, ")()","\n`","``")
                        
                        cat(knitr::knit(text = knitr::knit_expand(text = sub_chunk), 
                                        quiet = TRUE))
                        
                      }

```

---

# General inforamtion

---

**General data filtering and preparations** \
\
All sequenced samples were combined with the provided metadata (`r meta.path`). Only samples that was annotated as **1** (Sugar) or **2** (S&SEs) in column "*group*" where selected. If a sample (column "*UniqPartID*") was sequenced several time, the sequencing attempt with the highest total reads count was selected. \
\
In addition, factor columns "*Country*", "*Subject*", and interaction column "*GroupTime*" created with the function *interaction()* on "*Group*" and "*Time*" columns were added. The "*Time*" was encoded as the numeric representation of the month (`r sort(unique(meta.ls[[1]][["Time"]]))`) of sampling corresponding to CID. \
\
Taxa with less than `r min.reads.tax` reads across all samples were removed from the following analysis. As well as taxa assigned to "*Mitochondria*" and "*Chloroplast*", not assigned to any phylum, or assigned to kingdom other than "*Bacteria*" or "*Archaea*" were removed from the data set. \
\
\
**Data sub-sets** \
\
Three sub-sets of the data was prepared and used for the following data analysis. \
The sub-set dented as **all** includes all samples passed filtering described above. \
The sub-set dented as **CIDs_3** includes only samples after weight lost (CID_2, CID_3, and CID_4). Participants that with a missing sample at any selected CID were removed from this data set. \
The sub-set dented as **CIDs_4** includes all CIDs (CID_1, CID_2, CID_3, and CID_4). Participants that with a missing sample at any selected CID were removed from this data set.

\
\
\

---

### Number of samples per group {.tabset}

```{r, echo=FALSE, results='asis', fig.width=5, fig.height=5}

for (i.meta in names(meta.ls)){

  cat("#### Samples subset: ", i.meta, " {.tabset}\n")

  meta.inst <- meta.ls[[i.meta]]

  cat("##### Correlation", "\n\n")

  cor.tab <- meta.inst %>%
                  select(c("Group", "CID", "Country", "Plate"))

  pairs.panels(cor.tab, method = "spearman")

  cat("\n\n\n\n\n")


  for(i.grid in c("Country", "Plate")){

    cat("##### ", i.grid, "\n\n")

    n.samp.tab <- meta.inst %>%
                      select(all_of(c("Group", i.grid, "CID"))) %>%
                      table() %>%
                      as.data.frame() %>%
                      pivot_wider(names_from = c("CID"),
                                  values_from = Freq) %>%
                      arrange(Group)

    print(plot_kable(n.samp.tab, title = "**N Samples**"))

    cat("\n\n\n\n\n")

  }

  cat("##### Country & Plate", "\n\n")

  con.plat.df <- table(meta.inst$Country, meta.inst$Plate) %>%
                            as.data.frame.matrix() %>%
                              rownames_to_column("Country")

  print(plot_kable(con.plat.df, title = "**N Samples**"))

  cat("\n\n\n\n\n")

}

```

---

### Full metadata used per group {.tabset}

```{r, echo=FALSE, results='asis'}

for (i.meta in names(meta.ls)){

  cat("#### Samples subset: ", i.meta, "\n\n")

  n.samp.tab <- meta.ls[[i.meta]]

  print(plot_kable(n.samp.tab, title = "**Full metadata**"))

  cat("\n\n\n\n\n")

}

```

---



# Alpha diversity {.tabset}

---

Differences in alpha diversity trends between Sugar and S&SEs groups was assessed using *generate_alpha_trend_test_long()* function from the *MicrobiomeStat* package. In short, the method fits Linear Mix-effect Models (LMM) using a diversity metrics as the response variable. The method allows for addition of co-variates, analysis of linked data (time serious), as well as assessment of differences in diversity trends between groups (slopes interactions). \
\
As the first step `r alpha.met[-length(alpha.met)]`, and `r alpha.met[length(alpha.met)]` alpha diversity indexes were calculated from rarefied taxa tables on ASV and Genus taxonomic levels. The *mStat_calculate_alpha_diversity()* function was used to calculate alpha diversity indexes. \
\
The calculated alpha diversity indexes were used as a response variable in LMM models build by *generate_alpha_trend_test_long()* function. Variable `r var.use["Group"]` was used as the target variable (group.var), variable `r var.use["Subject"]` was used as the random effect (subject.var), variable `r var.use["Time"]` was used as the time variable (time.var), and variables `r var.use[c("Country", "Plate")]` were used as the adjustment variables (adj.vars). \
\
\
Results were visualized with *ggplot2*. Plots below show changes in alpha diversity indexes over time per individual, thin half transparent lines, and mean value per group, thick solid lines. Summary of LMM model results shown at the top of a corresponding plot. Only estimate and significance of interaction between Time variable and target group (Sugar) in comparison with the interaction between Time and reference variable (S&SEs) is shown. \
\

```{r, echo=FALSE, fig.width=7, fig.height=4, results='asis'}

for (i.ps in names(alpha.plot.ls)){

  cat("### Samples subset: ", i.ps, " {.tabset}\n")

  cat("\n\n\n\n\n")

  for(i.lvl in names(alpha.plot.ls[[i.ps]])) {

    cat("#### ", i.lvl,  "\n")

    plot(alpha.plot.ls[[i.ps]][[i.lvl]])

    cat("\n\n\n\n\n")

}}

```

\
\

# Beta diversity

---

To access differences in overall microbial composition between groups we used PERMANOVA type test as implemented in the *vegan* package on a dissimilarity matrix.
\
\
Dissimilarity matrices were build using `r used.dist[-length(used.dist)]`, and `r used.dist[length(used.dist)]` dissimilarity distances per samples sub-set. Then a Distance-based redundancy analysis (dbRDA) was preformed using *dbrda()* function from the *vegan* package, and the following model `r as.character(rda.form)[3]`. Significance and strength of grouping and interaction was assessed with PERMANOVA by terms as implemented in *anova.cca* function with `r nperm` permutations.
\
\
Plots below shows visualization constrained (dbRDA) and unconstrained (PCoA) ordinations. \
To create dbRDA plots the object created by *dbrda()* function was summarized with the *summary()* function. Site scores for the first two axes were extracted from the summary object and as a scatter plot (dots), and axis importance was used as an approximation of the captured variations. Samples from the same but individual different time points were connected by a line. Positions of vectors and centroids were extracted from the autoplot object created by the *ggvegan* package. Aspect ratio of the x and y axes were fixed with *coord_fixed()* to preserve data clustering as suggested by the authors of the *vegan* package.
\
\
The samples position (vectors) and centroids for PCoA plot were extracted from the object created by the *betadisper()* function from the *vegan* package. The samples were colored by the group variable, and connected centroids with lines. To aproximate the captured variation by each axis, relative eigen values for axis were used as was calculated by the *pcoa()* function from the *ape* package (pcoa\\$values\\$Relative_eig). Same as for dbRDA plots x and y axes aspect were fixed.
\
\
\

### RDA plots {.tabset}

```{r, echo=FALSE, fig.width=12, fig.height=12, results='asis'}

for (i.ps in names(rda.comb.plots.ls)){

  cat("#### Samples subset: ", i.ps, " {.tabset}\n")

  for(i.lvl in names(rda.comb.plots.ls[[i.ps]])) {

    cat("##### ", i.lvl,  "\n")

    p.ls.inst <- rda.comb.plots.ls[[i.ps]][[i.lvl]]

    p.ls.inst.f <- lapply(p.ls.inst, function(x) {x +
                                          theme(legend.position="none")})

    legd.inst <- get_legend(p.ls.inst[[1]])

    p.grid.1 <- plot_grid(plotlist = p.ls.inst.f, ncol = 2)

    p.grid.2 <- plot_grid(p.grid.1, legd.inst, ncol = 2, rel_widths = c(1, .1))

    plot(p.grid.2)

    cat("\n\n\n\n\n")

  }}
```


### PCoA plots {.tabset}

```{r, echo=FALSE, fig.width=12, fig.height=12, results='asis'}

for (i.ps in names(pcoa.comb.plots.ls)){

  cat("#### Samples subset: ", i.ps, " {.tabset}\n")

  cat("\n\n\n\n\n")

  for(i.lvl in names(pcoa.comb.plots.ls[[i.ps]])) {

    cat("##### ", i.lvl,  "\n")

    p.ls.inst <- pcoa.comb.plots.ls[[i.ps]][[i.lvl]]

    p.ls.inst.f <- lapply(p.ls.inst, function(x) {x +
                                          theme(legend.position="none")})

    legd.inst <- get_legend(p.ls.inst[[1]])

    p.grid.1 <- plot_grid(plotlist = p.ls.inst.f, ncol = 2)

    p.grid.2 <- plot_grid(p.grid.1, legd.inst, ncol = 2, rel_widths = c(1, .1))

    plot(p.grid.2)

    cat("\n\n\n\n\n")

  }}
```

\
\

### Per time point {.tabset}

To have a better understanding of the differences in microbial composition between groups at each time point, we performed PERMANOVA on subsets of samples corresponding to each time point. Subsets were take from the full set of samples, and dissimilarity matrices were calculated per each subset.
\
\
Three different PREMANOVA approaches were used: \
1. anova.cca on dbRDA with conditioned covariets: `r pair.forms[1]` \
2. adonis2 without covariets: `r pair.forms[2]` \
3. adonis2 with convariets: `r pair.forms[3]` \
\
Below are PCoA plots and summary table of PERMANOVA results.
\
\

```{r, echo=FALSE, fig.width=12, fig.height=12, results='asis'}

for (i.lvl in names(pcoa.pair.plots.arr)){

  cat("#### ", i.lvl, " {.tabset}\n")

  cat("##### Stat Summary \n\n")

  sum.tab <- filter(beta.stat.summary, .data[["Taxa Level"]] == i.lvl)

  print(plot_kable(sum.tab,
           title = "**Beta diversity per point summary**"))

  cat("\n\n\n\n\n")


  for(i.dist in names(pcoa.pair.plots.arr[[i.lvl]])) {

    cat("##### Distance: ", i.dist,  "\n")

    p.ls.inst <- pcoa.pair.plots.arr[[i.lvl]][[i.dist]]

    plot(p.ls.inst)

    cat("\n\n\n\n\n")

  }}
```

# Differential abundance {.tabset}

---

Differential abundance analysis was performed using "*LinDA*", and "*Maaslin2*"methods. Prior testing taxa with prevalence less than `r prev.da.cut.off` were removed. Taxa were considered significant if q-value was below or equal `r qvalue.cutoff`.
\
\
*Methods*
\
**LinDA**:
\
It is one of the recently developed methods that uses linear mixed effect models to account for the repeated measures and co-variets (`r adj.vars.ld`). The methods is implemented as a part of *MicrobiomeStat* package and included in several functions.
\
In short LinDA method uses linear regressions on Center log-ratio transformed data; identify a bias therm due to the compositional effect and corrects for it using mode of the regression coefficients across different taxa; afterwards it computes p-value. Note, in the paper stated that p-values are adjusted for multiple testing during the process, however, functions give you an option to further apply FDR adjustment, it is not clear if it is necessary to do.
\
\
Assumptions of the method:
1. Mode at 0 for the regression coefficients. \
2. Log linear model (linear relationships) on the absolute abundance. \
3. Not recommended to apply for datasets with small taxa count (less than 50)
\
\
Application of the method. \
The method was applied to find differences in taxa abundance *trends* between groups (Sugar vs S&SEs) with the function *generate_taxa_trend_test_long()*. 
\

Following heat maps show differential abundant taxa detected by different methods, on different taxonomic level.
\
\
\
**MaSsLin2**: \
uses log general linear models on normalized abundance. \
\
\
From the discussion with the authors of the method it could be interpreted that Maaslin2 is not well adapted to decipher interaction between slopes of a variable levels (https://forum.biobakery.org/t/does-maaslin2-supports-longitudinal-data-analysis/2432).
\
\
Here I used Maaslin2 as followed:
\
1. Find differences in taxa abundance between groups (Sugar vs S&SEs) per time point.
\
This is a simple model that doesn't account for repeated measures and would produced results similar to the ones produced by Wilcoxon test.
\
\

```{r, echo=FALSE, results='asis'}

for (i.lvl in names(heat.sum.ls)){

  cat("## ", i.lvl, " {.tabset}\n")

  cat("### Methods Summary\n\n")

  cat("\n", heat.sum.ls[[i.lvl]]$name, "\n\n\n")

  subchunkify(plot(heat.sum.ls[[i.lvl]]$plot),
                    fig_height = (heat.sum.ls[[i.lvl]]$nrow*0.2 + 3),
                    fig_width = (heat.sum.ls[[i.lvl]]$ncol*0.5 + 5))
  
  cat("\n\n\n\n\n")


  for(i.method in names(method.vis.ls[[i.lvl]])){

    cat("### Method: ", i.method, " {.tabset}\n\n")

    # Summary heat map
    cat("#### Summary\n\n")

    p1 <- method.vis.ls[[i.lvl]][[i.method]]$det_heat

    cat("\n", p1$name, "\n\n\n")

    subchunkify(plot(p1$plot),
                      fig_height = (p1$nrow*0.2 + 3),
                      fig_width = (p1$ncol*0.5 + 5))

    cat("\n\n\n\n\n")


    # Spaghetti plots
    cat("#### Spaghetti {.tabset}\n\n")

    for(i.norm in names(method.vis.ls[[i.lvl]][[i.method]][["spagg"]])){

      cat("##### Normalization: ", i.norm, "\n\n")

      p2 <- method.vis.ls[[i.lvl]][[i.method]][["spagg"]][[i.norm]]

      cat("\n", p2$name, "\n\n\n")

      subchunkify(suppressWarnings(plot(p2$plot)),
                        fig_height = (p2$nrow*2.25),
                        fig_width = 12)

      cat("\n\n\n\n\n")

    }

    # Composition heat maps
    cat("#### Composition {.tabset}\n\n")

    for(i.norm in names(method.vis.ls[[i.lvl]][[i.method]][["heat_comp"]])){

      cat("##### Normalization: ", i.norm, " {.tabset}\n\n")

      p3 <- method.vis.ls[[i.lvl]][[i.method]][["heat_comp"]][[i.norm]]

      for (i.set in names(p3)) {

      cat("###### Set: ", i.set, "\n\n")

      p4 <- p3[[i.set]]

      cat("\n", p4$name, "\n\n\n")

      subchunkify(plot(p4$plot),
                        fig_height = (p4$nrow*0.2 + 3),
                        fig_width = 15)

      cat("\n\n\n\n\n")
      }
      cat("\n\n\n\n\n")
    }
    cat("\n\n\n\n\n")
  }
  cat("\n\n\n\n\n")
}
```
